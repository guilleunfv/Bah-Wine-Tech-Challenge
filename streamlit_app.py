import os
import openai
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

# Configura√ß√£o da chave API da OpenAI
api_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("openai_api_key")
if not api_key:
    st.error("A chave API da OpenAI n√£o foi encontrada. Configure-a no `secrets` ou como vari√°vel de ambiente.")
    st.stop()

openai.api_key = api_key

# ----------------------------------------------------------
# PARTE 1: An√°lise de Dados de Exporta√ß√£o de Vinhos
# ----------------------------------------------------------

@st.cache_data
def carregar_dados():
    url = "https://drive.google.com/uc?id=1-mrtTLjOPh_XVk1mkDH00SUJxWkuOu5o"
    dados = pd.read_csv(url, delimiter=';', encoding='utf-8', quotechar='"')
    dados.columns = dados.columns.str.strip()
    return dados

# Carregar os dados
df = carregar_dados()

# Layout do app
st.title("üç∑ An√°lise de Exporta√ß√£o de Vinhos + Bah Chat")
st.markdown(
    """
    Bem-vindo ao **Bah Chat**, o chatbot e ferramenta de an√°lise de dados de exporta√ß√£o de vinhos brasileiros.
    Use os gr√°ficos interativos e interaja com o chatbot para explorar os dados de exporta√ß√£o de vinhos.
    """
)

# Dados gerais
st.subheader("üìä Dados Gerais de Exporta√ß√£o")
st.dataframe(df)

# Filtros interativos
st.sidebar.header("üîç Filtros Interativos")
anos = st.sidebar.multiselect(
    "Selecione os Anos", 
    df['A√±o'].unique(), 
    default=df['A√±o'].unique()
)
df_filtrado = df[df['A√±o'].isin(anos)]

paises = st.sidebar.multiselect(
    "Selecione os Pa√≠ses", 
    df['Pa√≠s'].unique(), 
    default=df['Pa√≠s'].unique()[:10]
)
df_filtrado = df_filtrado[df_filtrado['Pa√≠s'].isin(paises)]

st.subheader("üîé Dados Filtrados")
st.dataframe(df_filtrado)

# Gr√°fico 1: Tend√™ncia de Exporta√ß√£o
st.subheader("üìà Tend√™ncia de Exporta√ß√£o (US$ FOB por Ano)")
if not df_filtrado.empty:
    fig, ax = plt.subplots(figsize=(10, 4))
    df_group_ano = df_filtrado.groupby('A√±o')['Valor US$ FOB'].sum().sort_index()
    ax.plot(df_group_ano.index, df_group_ano.values, color='#8B0000', marker='o')
    ax.set_title("Tend√™ncia de Exporta√ß√£o de Vinhos", fontsize=16, color='#8B0000')
    ax.set_xlabel("Ano", fontsize=14)
    ax.set_ylabel("Valor Total (US$ FOB)", fontsize=14)
    st.pyplot(fig)
else:
    st.warning("N√£o h√° dados para exibir no gr√°fico.")

# Gr√°fico 2: Exporta√ß√£o por Pa√≠s
st.subheader("üåç Exporta√ß√£o por Pa√≠s")
if not df_filtrado.empty:
    fig, ax = plt.subplots(figsize=(10, 4))
    df_group_pais = df_filtrado.groupby('Pa√≠s')['Valor US$ FOB'].sum().sort_values(ascending=False).head(10)
    df_group_pais.plot(kind='bar', color='#A52A2A', ax=ax)
    ax.set_title("Top 10 Pa√≠ses de Destino", fontsize=16, color='#8B0000')
    ax.set_xlabel("Pa√≠s", fontsize=14)
    ax.set_ylabel("Valor Total (US$ FOB)", fontsize=14)
    st.pyplot(fig)
else:
    st.warning("N√£o h√° dados para exibir no gr√°fico.")

# ----------------------------------------------------------
# PARTE 2: Bah Chat
# ----------------------------------------------------------

st.subheader("ü§ñ Bah Chat")

# Fun√ß√£o para gerar resposta
def gerar_resposta(messages):
    """
    Gera uma resposta usando o modelo GPT-3.5 da OpenAI.
    """
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=messages,
        )
        return response["choices"][0]["message"]["content"]
    except Exception as e:
        return f"Erro ao conectar com o Bah Chat: {e}"

# Inicializa o hist√≥rico de mensagens
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": "Voc√™ √© um assistente √∫til para an√°lise de exporta√ß√£o de vinhos."}]

# Exibe as mensagens antigas
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Entrada do usu√°rio
prompt = st.chat_input("Digite sua pergunta ou solicita√ß√£o...")
if prompt:
    # Adiciona a mensagem do usu√°rio ao hist√≥rico
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Chama a API OpenAI para gerar a resposta
    resposta = gerar_resposta(st.session_state.messages)

    # Adiciona a resposta ao hist√≥rico e exibe
    st.session_state.messages.append({"role": "assistant", "content": resposta})
    with st.chat_message("assistant"):
        st.markdown(resposta)
